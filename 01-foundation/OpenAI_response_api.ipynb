{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da063c3c",
   "metadata": {},
   "source": [
    "## PROVIDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38199e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da400414",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3380a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"tell me a joke about Leonel\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01526b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did Leonel bring a ladder to the bar?\n",
      "\n",
      "Because he heard the drinks were on the house!\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04b9844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did Leonel bring a ladder to the bar?\\n\\nBecause he heard the drinks were on the house!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[0].content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ffb3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_091c9aecf6fdcf8b00697e914fd7f4819899357363955dde1e\",\n",
      "  \"created_at\": 1769902415.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_091c9aecf6fdcf8b00697e9150ef4c8198a751d22dae6952ee\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Why did Leonel bring a ladder to the bar?\\n\\nBecause he heard the drinks were on the house!\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"completed_at\": 1769902417.0,\n",
      "  \"conversation\": null,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"prompt_cache_retention\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 14,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 22,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 36\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"billing\": {\n",
      "    \"payer\": \"developer\"\n",
      "  },\n",
      "  \"frequency_penalty\": 0.0,\n",
      "  \"presence_penalty\": 0.0,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4465f",
   "metadata": {},
   "source": [
    "## CONFIGURE INPUT FOR LLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bed3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"cuantame una triste historia de un unicornio\"}\n",
    "]\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb0abb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hab√≠a una vez, en un bosque encantado, un unicornio llamado Lira. Era famoso entre los otros animales por su brillante cuerno plateado y su melena iridiscente. Todos los d√≠as, Lira correteaba alegremente por las praderas, haciendo que las flores florecieran a su paso.\n",
      "\n",
      "Sin embargo, su vida cambi√≥ cuando un oscuro hechizo cay√≥ sobre el bosque. Una bruja celosa, que no soportaba la belleza y la felicidad que irradiaba Lira, decidi√≥ atraparlo. Un d√≠a, mientras el unicornio pastaba, la bruja lanz√≥ un encantamiento que lo hizo perder su luz. Lira se convirti√≥ en una sombra de lo que era, su melena perdi√≥ su brillo y su coraz√≥n se llen√≥ de tristeza.\n",
      "\n",
      "A medida que pasaban los d√≠as, el bosque se torn√≥ gris y los animales no pod√≠an alegrarse como antes. Lira, sinti√©ndose solo y perdido, se alej√≥ de sus amigos, quien hab√≠a pensado que su tristeza era contagiosa. A pesar de su sufrimiento, Lira nunca dej√≥ de so√±ar con recuperar su luz y la felicidad del bosque.\n",
      "\n",
      "Un d√≠a, mientras lamentaba su suerte en un claro, escuch√≥ el suave murmullo de un arroyo. Al acercarse, vio su reflejo en el agua y record√≥ qui√©n era realmente. Intenta recuperar la esperanza y, con cada l√°grima que ca√≠a, el arroyo empez√≥ a brillar con un resplandor nuevo. Lira se dio cuenta de que, aunque el hechizo le hab√≠a robado su luz, su esp√≠ritu segu√≠a intacto.\n",
      "\n",
      "Decidi√≥ que no se dejar√≠a vencer. Con su coraz√≥n lleno de valent√≠a, se enfrent√≥ a la bruja. Su amor por el bosque y sus amigos era m√°s fuerte que cualquier hechizo. Al sentir su determinaci√≥n, la bruja, asombrada, se dio cuenta de que la belleza verdadera nunca puede ser apagada. Con un gesto, deshizo el encantamiento y el bosque recuper√≥ su esplendor.\n",
      "\n",
      "Lira volvi√≥ a ser el unicornio radiante que siempre hab√≠a sido, pero esta vez con un brillo m√°s profundo, el de alguien que ha enfrentado la tristeza y ha salido fortalecido. Aunque la vida nunca fue la misma despu√©s de aquel encuentro, Lira aprendi√≥ que incluso en los momentos m√°s oscuros, siempre hay un camino hacia la luz si se tiene el coraje suficiente para buscarlo. Y as√≠, el bosque floreci√≥ de nuevo, lleno de color y amistad, pero sobre todo, de la esperanza que Lira hab√≠a rehecho.\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46efe32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√ârase una vez en un reino lejano, un hermoso unicornio llamado Lira. Su pelaje era blanco como la nieve y su cuerno brillaba con todos los colores del arco√≠ris. Lira viv√≠a en un bosque m√°gico donde los animales la adoraban por su bondad y generosidad.\n",
      "\n",
      "Sin embargo, hab√≠a un secreto que Lira guardaba muy celosamente. A pesar de su esplendor, se sent√≠a profundamente sola. Otros unicornios sol√≠an evitarla, temerosos de que su belleza y magia fueran solo un mito. \n",
      "\n",
      "Un d√≠a, mientras exploraba una parte remota del bosque, Lira conoci√≥ a una peque√±a ni√±a llamada Ana. Ana estaba triste porque su mascota, un conejito, hab√≠a desaparecido. Al ver la tristeza en su rostro, Lira decidi√≥ ayudarla y juntas comenzaron a buscar por el bosque.\n",
      "\n",
      "A medida que pasaban los d√≠as, Lira y Ana forjaron un lazo especial. Ana ve√≠a a Lira no solo como un unicornio m√°gico, sino como una amiga. Sin embargo, un d√≠a, en medio de su b√∫squeda, Ana se cay√≥ en un arroyo y se lastim√≥ la pierna. Lira, preocupada, trat√≥ de ayudarla, pero la ni√±a le pidi√≥ que se fuera, que volver√≠a a estar bien sola.\n",
      "\n",
      "Descorazonada, Lira vio c√≥mo Ana se alej√≥, y su coraz√≥n se llen√≥ de tristeza. Con el tiempo, Ana san√≥, pero nunca regres√≥ al bosque. Lira quedaba sola, cada d√≠a saliendo a buscar a su amiga, pero solo hallando ecos del pasado.\n",
      "\n",
      "El tiempo pas√≥ en aquel bosque m√°gico, y Lira se convirti√≥ en una leyenda. Los animales a√∫n hablaban de su belleza, pero pocos conoc√≠an la profunda soledad que experimentaba. En su coraz√≥n, Lira siempre llevar√≠a el recuerdo de la peque√±a ni√±a que le mostr√≥ lo que significaba la amistad.\n",
      "\n",
      "As√≠, el unicornio continu√≥ vagando por el bosque, buscando en cada rinc√≥n la sonrisa de Ana, esperando que alg√∫n d√≠a, su amiga regresara y le devolviera la luz que una vez hab√≠a encontrado en el compa√±erismo."
     ]
    }
   ],
   "source": [
    "stream = openai_client.responses.create(\n",
    "    model ='gpt-4o-mini',\n",
    "    input = messages,\n",
    "    stream = True\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if hasattr(event, 'delta'):\n",
    "        print(event.delta, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d7b0a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseUsage(input_tokens=17, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=534, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=551)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb11df8",
   "metadata": {},
   "source": [
    "## GPT MODELS PRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd2d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PRICES = {\n",
    "    \"gpt-4o-mini\": {\"input\": 0.15, \"output\": 0.60},\n",
    "    \"gpt-5-nano\": {\"input\": 0.075, \"output\": 0.30},\n",
    "    \"gpt-5-mini\": {\"input\": 0.25, \"output\": 2.00},\n",
    "    \"gpt-5.2\": {\"input\": 1.75, \"output\": 14.00},\n",
    "    \"gpt-5.2-pro\": {\"input\": 21.00, \"output\": 168.00},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec8565d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(model_name: str,\n",
    "                   input_tokens: int,\n",
    "                   output_tokens: int) -> float:\n",
    "    \n",
    "    prices = MODEL_PRICES[model_name.lower()]\n",
    "    \n",
    "    if not prices:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    input_cost = (input_tokens / 1_000_000) * prices[\"input\"]\n",
    "    output_cost = (output_tokens / 1_000_000) * prices[\"output\"]\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26e79188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost of the API call: $0.000323\n"
     ]
    }
   ],
   "source": [
    "usage = response.usage\n",
    "\n",
    "cost = calculate_cost(\"gpt-4o-mini\",\n",
    "               input_tokens=usage.input_tokens,\n",
    "               output_tokens=usage.output_tokens)\n",
    "\n",
    "print(f\"Total cost of the API call: ${cost:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e3641",
   "metadata": {},
   "source": [
    "## FUNCTION PRICES IN EVENT STREAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63ffb4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√ârase una vez en un bosque encantado, un unicornio llamado Luna. Pose√≠a un hermoso cuerno que brillaba como las estrellas y su pelaje era blanco como la nieve. Luna era conocida por su bondad y su habilidad para curar a otros seres m√°gicos con su toque.\n",
      "\n",
      "Un d√≠a, mientras exploraba el bosque, Luna se encontr√≥ con un peque√±o duende que lloraba desconsoladamente. Al acercarse, el duende le cont√≥ que hab√≠a perdido a su mejor amigo, un p√°jaro de colores vibrantes, que hab√≠a volado demasiado lejos y no pod√≠a regresar. Luna, conmovida por su tristeza, decidi√≥ ayudarlo.\n",
      "\n",
      "Juntos, buscaron al p√°jaro por d√≠as, cruzando r√≠os y monta√±as. Pero, a pesar de todos sus esfuerzos, no lograron encontrarlo. El duende se desanim√≥, y su llanto se transform√≥ en una profunda tristeza. Luna, sintiendo el dolor de su amigo, se esforz√≥ por animarlo, pero cada intento era in√∫til.\n",
      "\n",
      "Con el tiempo, el duende dej√≥ de sonre√≠r y el brillo en sus ojos se apag√≥. Luna, desolada, entendi√≥ que no pod√≠a curar su tristeza. Una noche, mientras miraba las estrellas, sinti√≥ un vac√≠o en su coraz√≥n. El bosque, que alguna vez hab√≠a sido su hogar feliz, se torn√≥ gris y silencioso.\n",
      "\n",
      "Un d√≠a, Luna decidi√≥ abandonar el bosque, sintiendo que su luz ya no brillaba. Se intern√≥ en una parte lejana del bosque, donde nunca nadie la hab√≠a visto. Y all√≠, en soledad, sigui√≥ buscando maneras de sanar otros corazones, pero siempre sin el aquel brillo que una vez la hab√≠a caracterizado.\n",
      "\n",
      "Los a√±os pasaron, y aunque Luna sigui√≥ haciendo el bien, siempre le falt√≥ algo. Su coraz√≥n, tan lleno de amor, estaba triste por la p√©rdida de su amigo, y su luz ya no alcanzaba a iluminar como antes. Y as√≠, el bosque encantado aprendi√≥ a recordarla, no solo como el hermoso unicornio que sanaba, sino como un s√≠mbolo de la tristeza de haber perdido lo que m√°s amaba.\n",
      "\n",
      "Y cada noche, las estrellas brillaban un poco m√°s en el cielo, como si, en honor a Luna, quisieran recordarle que aunque la tristeza puede apagar la luz, el amor que compartimos nunca se pierde del todo."
     ]
    }
   ],
   "source": [
    "stream = openai_client.responses.create(\n",
    "    model ='gpt-4o-mini',\n",
    "    input = messages,\n",
    "    stream = True\n",
    ")\n",
    "\n",
    "response = None\n",
    "\n",
    "for event in stream:\n",
    "    if hasattr(event, 'delta'):\n",
    "        print(event.delta, end='')\n",
    "    if hasattr(event, 'response'):\n",
    "        response = event.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc73f08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseUsage(input_tokens=17, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=494, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=511)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d0084",
   "metadata": {},
   "source": [
    "## USE ROLS FOR GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8d726e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "isntructions = \"asegurate de agregar emojis\"\n",
    "user_prompt = \"que accion entre amd, intel y nvdia deberia comprar hoy con ganancias a 6 meses?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": isntructions},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bc7a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elegir entre AMD, Intel y NVIDIA depende de varios factores, pero aqu√≠ tienes un resumen de cada uno:\n",
      "\n",
      "1. **AMD (Advanced Micro Devices)** üíª:\n",
      "   - Fuerte crecimiento en el mercado de procesadores y tarjetas gr√°ficas.\n",
      "   - Innovaciones constantes y buenos pron√≥sticos a largo plazo.\n",
      "\n",
      "2. **Intel** üèóÔ∏è:\n",
      "   - L√≠der en el mercado de CPUs, pero ha perdido terreno frente a AMD en los √∫ltimos a√±os.\n",
      "   - Enfoque en recuperaci√≥n y nuevas tecnolog√≠as, como semiconductores avanzados.\n",
      "\n",
      "3. **NVIDIA** üéÆ:\n",
      "   - Gran l√≠der en el mercado de GPUs, especialmente en IA y gaming.\n",
      "   - Alto crecimiento y demanda en la inteligencia artificial y el aprendizaje autom√°tico.\n",
      "\n",
      "### Recomendaci√≥n:\n",
      "Si buscas una inversi√≥n m√°s arriesgada con potencial de alto crecimiento, **NVIDIA** podr√≠a ser la mejor opci√≥n debido a su liderazgo en IA y gaming. Sin embargo, si prefieres una opci√≥n m√°s estable y con un crecimiento s√≥lido, **AMD** tambi√©n es prometedora.\n",
      "\n",
      "Recuerda hacer tu propia investigaci√≥n y considerar factores como el an√°lisis t√©cnico y fundamental antes de invertir. ¬°Buena suerte! üìà‚ú®\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de501cd",
   "metadata": {},
   "source": [
    "## LLMS ARE STATELESS, llm don't remember previus conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78dc3923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Hola, Leonel! üëã ¬øC√≥mo est√°s? ¬øEn qu√© te puedo ayudar hoy? üòä\n"
     ]
    }
   ],
   "source": [
    "isntructions = \"asegurate de agregar emojis\"\n",
    "user_prompt = \"mi nombre es Leonel \"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": isntructions},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=messages\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "525eb834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tengo acceso a informaci√≥n personal, as√≠ que no s√© tu nombre. Pero si quieres, puedes dec√≠rmelo. ¬øEn qu√© puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=\"Cual es mi nombre?\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c1987f",
   "metadata": {},
   "source": [
    "## Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f534b314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Hola, Leonel! üëã ¬øC√≥mo est√°s? ¬øEn qu√© puedo ayudarte hoy? üòä\n"
     ]
    }
   ],
   "source": [
    "isntructions = \"asegurate de agregar emojis\"\n",
    "user_prompt = \"mi nombre es Leonel \"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": isntructions},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=messages\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "591f0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.extend(response.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "372c24e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'asegurate de agregar emojis'},\n",
       " {'role': 'user', 'content': 'mi nombre es Leonel '},\n",
       " ResponseOutputMessage(id='msg_031825f5288bca0300697e9d9da698819a9f0799ad9c0b5f21', content=[ResponseOutputText(annotations=[], text='¬°Hola, Leonel! üëã ¬øC√≥mo est√°s? ¬øEn qu√© puedo ayudarte hoy? üòä', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63de5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "    {\"role\": \"user\", \"content\": \"Cual es mi nombre?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b8440ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'asegurate de agregar emojis'},\n",
       " {'role': 'user', 'content': 'mi nombre es Leonel '},\n",
       " ResponseOutputMessage(id='msg_031825f5288bca0300697e9d9da698819a9f0799ad9c0b5f21', content=[ResponseOutputText(annotations=[], text='¬°Hola, Leonel! üëã ¬øC√≥mo est√°s? ¬øEn qu√© puedo ayudarte hoy? üòä', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'),\n",
       " {'role': 'user', 'content': 'Cual es mi nombre?'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f58b68bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tu nombre es Leonel. üòä‚ú®\n"
     ]
    }
   ],
   "source": [
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=messages\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34fb02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineering-buildcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
